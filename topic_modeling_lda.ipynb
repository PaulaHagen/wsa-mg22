{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCTIS needs Python Version 3.10!!\n",
    "# See requirements.txt for package installation.\n",
    "\n",
    "from src.data_cleaning import load_data, clean_duplicates\n",
    "from src.data_preprocessing import preprocess, split_in_time_points\n",
    "from src.data_transformation import add_bigrams, filter_extreme_values, transform_in_octis_format, save_doc_ids_dates\n",
    "from src.lda_octis import find_best_model, load_octis_data, update_model, calculate_coherence\n",
    "from src.topic_analysis import find_emerging_topics, find_trending_topics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download nltk stopwords, tokenization and PoS-Taggging\n",
    "#nltk.download('popular')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip3 install spacy\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>coverDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food systems are responsible for a third of gl...</td>\n",
       "      <td>We have developed a new global food emissions ...</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital transformation: A multidisciplinary re...</td>\n",
       "      <td>Digital transformation and resultant business ...</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predicted growth in plastic waste exceeds effo...</td>\n",
       "      <td>Plastic pollution is a planetary threat, affec...</td>\n",
       "      <td>2020-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepAR: Probabilistic forecasting with autoreg...</td>\n",
       "      <td>Probabilistic forecasting, i.e., estimating a ...</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research opportunities for a more resilient po...</td>\n",
       "      <td>Purpose: The COVID-19 crisis has caused major ...</td>\n",
       "      <td>2020-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82593</th>\n",
       "      <td>Resilient metallurgical supplier management - ...</td>\n",
       "      <td>The resilient supplier management is a crucial...</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82594</th>\n",
       "      <td>Optimization of photochemical degradation of d...</td>\n",
       "      <td>The objective of this research work is to appl...</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82595</th>\n",
       "      <td>Goal Geometric Programming</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82596</th>\n",
       "      <td>Eating less meat ‘to save the planet’: Studyin...</td>\n",
       "      <td>Recently published healthy eating guidelines i...</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82597</th>\n",
       "      <td>Algorithm customization to audit database in h...</td>\n",
       "      <td>The teaching evaluation tests, that have been ...</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Food systems are responsible for a third of gl...   \n",
       "1      Digital transformation: A multidisciplinary re...   \n",
       "2      Predicted growth in plastic waste exceeds effo...   \n",
       "3      DeepAR: Probabilistic forecasting with autoreg...   \n",
       "4      Research opportunities for a more resilient po...   \n",
       "...                                                  ...   \n",
       "82593  Resilient metallurgical supplier management - ...   \n",
       "82594  Optimization of photochemical degradation of d...   \n",
       "82595                         Goal Geometric Programming   \n",
       "82596  Eating less meat ‘to save the planet’: Studyin...   \n",
       "82597  Algorithm customization to audit database in h...   \n",
       "\n",
       "                                             description   coverDate  \n",
       "0      We have developed a new global food emissions ...  2021-03-01  \n",
       "1      Digital transformation and resultant business ...  2021-01-01  \n",
       "2      Plastic pollution is a planetary threat, affec...  2020-09-01  \n",
       "3      Probabilistic forecasting, i.e., estimating a ...  2020-07-01  \n",
       "4      Purpose: The COVID-19 crisis has caused major ...  2020-06-19  \n",
       "...                                                  ...         ...  \n",
       "82593  The resilient supplier management is a crucial...  2020-01-01  \n",
       "82594  The objective of this research work is to appl...  2020-01-01  \n",
       "82595                                               None  2019-01-01  \n",
       "82596  Recently published healthy eating guidelines i...  2019-01-01  \n",
       "82597  The teaching evaluation tests, that have been ...  2019-01-01  \n",
       "\n",
       "[82598 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Scopus Data (82.598 papers)\n",
    "df = load_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None values removed.\n",
      "Number of (title + desc) duplicates: 118. Duplicates Removed.\n",
      "Dataframe has now {len(clean_df)} entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>coverDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food systems are responsible for a third of gl...</td>\n",
       "      <td>We have developed a new global food emissions ...</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital transformation: A multidisciplinary re...</td>\n",
       "      <td>Digital transformation and resultant business ...</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Predicted growth in plastic waste exceeds effo...</td>\n",
       "      <td>Plastic pollution is a planetary threat, affec...</td>\n",
       "      <td>2020-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeepAR: Probabilistic forecasting with autoreg...</td>\n",
       "      <td>Probabilistic forecasting, i.e., estimating a ...</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research opportunities for a more resilient po...</td>\n",
       "      <td>Purpose: The COVID-19 crisis has caused major ...</td>\n",
       "      <td>2020-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82592</th>\n",
       "      <td>A multi-period stochastic casualty evacuation ...</td>\n",
       "      <td>In this paper, we propose a new optimization a...</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82593</th>\n",
       "      <td>Resilient metallurgical supplier management - ...</td>\n",
       "      <td>The resilient supplier management is a crucial...</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82594</th>\n",
       "      <td>Optimization of photochemical degradation of d...</td>\n",
       "      <td>The objective of this research work is to appl...</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82596</th>\n",
       "      <td>Eating less meat ‘to save the planet’: Studyin...</td>\n",
       "      <td>Recently published healthy eating guidelines i...</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82597</th>\n",
       "      <td>Algorithm customization to audit database in h...</td>\n",
       "      <td>The teaching evaluation tests, that have been ...</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Food systems are responsible for a third of gl...   \n",
       "1      Digital transformation: A multidisciplinary re...   \n",
       "2      Predicted growth in plastic waste exceeds effo...   \n",
       "3      DeepAR: Probabilistic forecasting with autoreg...   \n",
       "4      Research opportunities for a more resilient po...   \n",
       "...                                                  ...   \n",
       "82592  A multi-period stochastic casualty evacuation ...   \n",
       "82593  Resilient metallurgical supplier management - ...   \n",
       "82594  Optimization of photochemical degradation of d...   \n",
       "82596  Eating less meat ‘to save the planet’: Studyin...   \n",
       "82597  Algorithm customization to audit database in h...   \n",
       "\n",
       "                                             description   coverDate  \n",
       "0      We have developed a new global food emissions ...  2021-03-01  \n",
       "1      Digital transformation and resultant business ...  2021-01-01  \n",
       "2      Plastic pollution is a planetary threat, affec...  2020-09-01  \n",
       "3      Probabilistic forecasting, i.e., estimating a ...  2020-07-01  \n",
       "4      Purpose: The COVID-19 crisis has caused major ...  2020-06-19  \n",
       "...                                                  ...         ...  \n",
       "82592  In this paper, we propose a new optimization a...  2020-01-01  \n",
       "82593  The resilient supplier management is a crucial...  2020-01-01  \n",
       "82594  The objective of this research work is to appl...  2020-01-01  \n",
       "82596  Recently published healthy eating guidelines i...  2019-01-01  \n",
       "82597  The teaching evaluation tests, that have been ...  2019-01-01  \n",
       "\n",
       "[80075 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates and None values\n",
    "corpus = clean_duplicates(df)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Remove all digit-only chars, special chars, diacritics\n",
    "### 2. Filter terms with 2-30 chars\n",
    "### 3. Strip multiple whitespaces, transform to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tokenization, PoS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Stop word filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>coverDate</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>desc_tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food systems are responsible for third of glob...</td>\n",
       "      <td>we have developed new global food emissions da...</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>[(food, NN), (system, NNS), (responsible, JJ),...</td>\n",
       "      <td>[(develop, VBN), (new, JJ), (global, JJ), (foo...</td>\n",
       "      <td>[food, system, responsible, third, global, ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>digital multidisciplinary reflection and resea...</td>\n",
       "      <td>digital transformation and resultant business ...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>[(digital, JJ), (multidisciplinary, JJ), (refl...</td>\n",
       "      <td>[(digital, JJ), (transformation, NN), (resulta...</td>\n",
       "      <td>[digital, multidisciplinary, reflection, resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predicted growth in plastic waste exceeds effo...</td>\n",
       "      <td>plastic pollution is planetary affecting nearl...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>[(predicted, JJ), (growth, NN), (plastic, JJ),...</td>\n",
       "      <td>[(plastic, JJ), (pollution, NN), (planetary, J...</td>\n",
       "      <td>[predicted, growth, plastic, waste, exceeds, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probabilistic forecasting with autoregressive ...</td>\n",
       "      <td>probabilistic estimating time future probabili...</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>[(probabilistic, JJ), (forecasting, NN), (auto...</td>\n",
       "      <td>[(probabilistic, JJ), (estimating, NN), (time,...</td>\n",
       "      <td>[probabilistic, forecasting, autoregressive, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>research opportunities for more resilient supp...</td>\n",
       "      <td>the crisis has caused major supply chain and t...</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>[(research, NN), (opportunity, NNS), (resilien...</td>\n",
       "      <td>[(crisis, NN), (cause, VBN), (major, JJ), (sup...</td>\n",
       "      <td>[research, opportunity, resilient, supply, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82592</th>\n",
       "      <td>stochastic casualty evacuation network design ...</td>\n",
       "      <td>in this we propose new optimization approach f...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(stochastic, JJ), (casualty, NN), (evacuation...</td>\n",
       "      <td>[(propose, VBP), (new, JJ), (optimization, NN)...</td>\n",
       "      <td>[stochastic, casualty, evacuation, network, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82593</th>\n",
       "      <td>resilient metallurgical supplier management re...</td>\n",
       "      <td>the resilient supplier management is crucial p...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(resilient, JJ), (metallurgical, JJ), (suppli...</td>\n",
       "      <td>[(resilient, NN), (supplier, NN), (management,...</td>\n",
       "      <td>[resilient, metallurgical, supplier, managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82594</th>\n",
       "      <td>optimization of photochemical degradation of d...</td>\n",
       "      <td>the objective of this research work is to appl...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(optimization, NN), (photochemical, JJ), (deg...</td>\n",
       "      <td>[(objective, NN), (research, NN), (work, NN), ...</td>\n",
       "      <td>[optimization, photochemical, degradation, dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82596</th>\n",
       "      <td>eating less meat save the studying the develop...</td>\n",
       "      <td>recently published healthy eating guidelines i...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[(eat, VBG), (less, JJR), (meat, NN), (save, V...</td>\n",
       "      <td>[(publish, VBN), (healthy, JJ), (eat, VBG), (g...</td>\n",
       "      <td>[eat, less, meat, save, study, development, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82597</th>\n",
       "      <td>algorithm customization to audit database in h...</td>\n",
       "      <td>the teaching evaluation that have been applied...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[(algorithm, JJ), (customization, NN), (audit,...</td>\n",
       "      <td>[(teaching, NN), (evaluation, NN), (apply, VBN...</td>\n",
       "      <td>[algorithm, customization, audit, database, hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80075 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      food systems are responsible for third of glob...   \n",
       "1      digital multidisciplinary reflection and resea...   \n",
       "2      predicted growth in plastic waste exceeds effo...   \n",
       "3      probabilistic forecasting with autoregressive ...   \n",
       "4      research opportunities for more resilient supp...   \n",
       "...                                                  ...   \n",
       "82592  stochastic casualty evacuation network design ...   \n",
       "82593  resilient metallurgical supplier management re...   \n",
       "82594  optimization of photochemical degradation of d...   \n",
       "82596  eating less meat save the studying the develop...   \n",
       "82597  algorithm customization to audit database in h...   \n",
       "\n",
       "                                             description   coverDate  \\\n",
       "0      we have developed new global food emissions da...  2021-03-01   \n",
       "1      digital transformation and resultant business ...  2021-01-01   \n",
       "2      plastic pollution is planetary affecting nearl...  2020-09-01   \n",
       "3      probabilistic estimating time future probabili...  2020-07-01   \n",
       "4      the crisis has caused major supply chain and t...  2020-06-19   \n",
       "...                                                  ...         ...   \n",
       "82592  in this we propose new optimization approach f...  2020-01-01   \n",
       "82593  the resilient supplier management is crucial p...  2020-01-01   \n",
       "82594  the objective of this research work is to appl...  2020-01-01   \n",
       "82596  recently published healthy eating guidelines i...  2019-01-01   \n",
       "82597  the teaching evaluation that have been applied...  2019-01-01   \n",
       "\n",
       "                                            title_tokens  \\\n",
       "0      [(food, NN), (system, NNS), (responsible, JJ),...   \n",
       "1      [(digital, JJ), (multidisciplinary, JJ), (refl...   \n",
       "2      [(predicted, JJ), (growth, NN), (plastic, JJ),...   \n",
       "3      [(probabilistic, JJ), (forecasting, NN), (auto...   \n",
       "4      [(research, NN), (opportunity, NNS), (resilien...   \n",
       "...                                                  ...   \n",
       "82592  [(stochastic, JJ), (casualty, NN), (evacuation...   \n",
       "82593  [(resilient, JJ), (metallurgical, JJ), (suppli...   \n",
       "82594  [(optimization, NN), (photochemical, JJ), (deg...   \n",
       "82596  [(eat, VBG), (less, JJR), (meat, NN), (save, V...   \n",
       "82597  [(algorithm, JJ), (customization, NN), (audit,...   \n",
       "\n",
       "                                             desc_tokens  \\\n",
       "0      [(develop, VBN), (new, JJ), (global, JJ), (foo...   \n",
       "1      [(digital, JJ), (transformation, NN), (resulta...   \n",
       "2      [(plastic, JJ), (pollution, NN), (planetary, J...   \n",
       "3      [(probabilistic, JJ), (estimating, NN), (time,...   \n",
       "4      [(crisis, NN), (cause, VBN), (major, JJ), (sup...   \n",
       "...                                                  ...   \n",
       "82592  [(propose, VBP), (new, JJ), (optimization, NN)...   \n",
       "82593  [(resilient, NN), (supplier, NN), (management,...   \n",
       "82594  [(objective, NN), (research, NN), (work, NN), ...   \n",
       "82596  [(publish, VBN), (healthy, JJ), (eat, VBG), (g...   \n",
       "82597  [(teaching, NN), (evaluation, NN), (apply, VBN...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [food, system, responsible, third, global, ant...  \n",
       "1      [digital, multidisciplinary, reflection, resea...  \n",
       "2      [predicted, growth, plastic, waste, exceeds, e...  \n",
       "3      [probabilistic, forecasting, autoregressive, r...  \n",
       "4      [research, opportunity, resilient, supply, cha...  \n",
       "...                                                  ...  \n",
       "82592  [stochastic, casualty, evacuation, network, de...  \n",
       "82593  [resilient, metallurgical, supplier, managemen...  \n",
       "82594  [optimization, photochemical, degradation, dai...  \n",
       "82596  [eat, less, meat, save, study, development, su...  \n",
       "82597  [algorithm, customization, audit, database, hi...  \n",
       "\n",
       "[80075 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes ~4 minutes!\n",
    "preprocessed_corpus = preprocess(corpus)\n",
    "# Save corpus in file to avoid long run time (pickle preserves the data structure more accurately -> able to handle complex file types (e.g., lists)\n",
    "preprocessed_corpus.to_pickle('Data/corpus.pkl')\n",
    "preprocessed_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Transform into Bigrams and DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Extreme Value Filtering -> Before DTM so Kernel doesn't crash!\n",
    "Plus divide data into time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>coverDate</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>desc_tokens</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food systems are responsible for third of glob...</td>\n",
       "      <td>we have developed new global food emissions da...</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>[(food, NN), (system, NNS), (responsible, JJ),...</td>\n",
       "      <td>[(develop, VBN), (new, JJ), (global, JJ), (foo...</td>\n",
       "      <td>[food, system, responsible, third, global, ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>digital multidisciplinary reflection and resea...</td>\n",
       "      <td>digital transformation and resultant business ...</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>[(digital, JJ), (multidisciplinary, JJ), (refl...</td>\n",
       "      <td>[(digital, JJ), (transformation, NN), (resulta...</td>\n",
       "      <td>[digital, multidisciplinary, reflection, resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predicted growth in plastic waste exceeds effo...</td>\n",
       "      <td>plastic pollution is planetary affecting nearl...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>[(predicted, JJ), (growth, NN), (plastic, JJ),...</td>\n",
       "      <td>[(plastic, JJ), (pollution, NN), (planetary, J...</td>\n",
       "      <td>[predicted, growth, plastic, waste, exceeds, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>probabilistic forecasting with autoregressive ...</td>\n",
       "      <td>probabilistic estimating time future probabili...</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>[(probabilistic, JJ), (forecasting, NN), (auto...</td>\n",
       "      <td>[(probabilistic, JJ), (estimating, NN), (time,...</td>\n",
       "      <td>[probabilistic, forecasting, autoregressive, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>research opportunities for more resilient supp...</td>\n",
       "      <td>the crisis has caused major supply chain and t...</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>[(research, NN), (opportunity, NNS), (resilien...</td>\n",
       "      <td>[(crisis, NN), (cause, VBN), (major, JJ), (sup...</td>\n",
       "      <td>[research, opportunity, resilient, supply, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82592</th>\n",
       "      <td>stochastic casualty evacuation network design ...</td>\n",
       "      <td>in this we propose new optimization approach f...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(stochastic, JJ), (casualty, NN), (evacuation...</td>\n",
       "      <td>[(propose, VBP), (new, JJ), (optimization, NN)...</td>\n",
       "      <td>[stochastic, casualty, evacuation, network, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82593</th>\n",
       "      <td>resilient metallurgical supplier management re...</td>\n",
       "      <td>the resilient supplier management is crucial p...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(resilient, JJ), (metallurgical, JJ), (suppli...</td>\n",
       "      <td>[(resilient, NN), (supplier, NN), (management,...</td>\n",
       "      <td>[resilient, metallurgical, supplier, managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82594</th>\n",
       "      <td>optimization of photochemical degradation of d...</td>\n",
       "      <td>the objective of this research work is to appl...</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[(optimization, NN), (photochemical, JJ), (deg...</td>\n",
       "      <td>[(objective, NN), (research, NN), (work, NN), ...</td>\n",
       "      <td>[optimization, photochemical, degradation, dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82596</th>\n",
       "      <td>eating less meat save the studying the develop...</td>\n",
       "      <td>recently published healthy eating guidelines i...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[(eat, VBG), (less, JJR), (meat, NN), (save, V...</td>\n",
       "      <td>[(publish, VBN), (healthy, JJ), (eat, VBG), (g...</td>\n",
       "      <td>[eat, less, meat, save, study, development, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82597</th>\n",
       "      <td>algorithm customization to audit database in h...</td>\n",
       "      <td>the teaching evaluation that have been applied...</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[(algorithm, JJ), (customization, NN), (audit,...</td>\n",
       "      <td>[(teaching, NN), (evaluation, NN), (apply, VBN...</td>\n",
       "      <td>[algorithm, customization, audit, database, hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80075 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      food systems are responsible for third of glob...   \n",
       "1      digital multidisciplinary reflection and resea...   \n",
       "2      predicted growth in plastic waste exceeds effo...   \n",
       "3      probabilistic forecasting with autoregressive ...   \n",
       "4      research opportunities for more resilient supp...   \n",
       "...                                                  ...   \n",
       "82592  stochastic casualty evacuation network design ...   \n",
       "82593  resilient metallurgical supplier management re...   \n",
       "82594  optimization of photochemical degradation of d...   \n",
       "82596  eating less meat save the studying the develop...   \n",
       "82597  algorithm customization to audit database in h...   \n",
       "\n",
       "                                             description   coverDate  \\\n",
       "0      we have developed new global food emissions da...  2021-03-01   \n",
       "1      digital transformation and resultant business ...  2021-01-01   \n",
       "2      plastic pollution is planetary affecting nearl...  2020-09-01   \n",
       "3      probabilistic estimating time future probabili...  2020-07-01   \n",
       "4      the crisis has caused major supply chain and t...  2020-06-19   \n",
       "...                                                  ...         ...   \n",
       "82592  in this we propose new optimization approach f...  2020-01-01   \n",
       "82593  the resilient supplier management is crucial p...  2020-01-01   \n",
       "82594  the objective of this research work is to appl...  2020-01-01   \n",
       "82596  recently published healthy eating guidelines i...  2019-01-01   \n",
       "82597  the teaching evaluation that have been applied...  2019-01-01   \n",
       "\n",
       "                                            title_tokens  \\\n",
       "0      [(food, NN), (system, NNS), (responsible, JJ),...   \n",
       "1      [(digital, JJ), (multidisciplinary, JJ), (refl...   \n",
       "2      [(predicted, JJ), (growth, NN), (plastic, JJ),...   \n",
       "3      [(probabilistic, JJ), (forecasting, NN), (auto...   \n",
       "4      [(research, NN), (opportunity, NNS), (resilien...   \n",
       "...                                                  ...   \n",
       "82592  [(stochastic, JJ), (casualty, NN), (evacuation...   \n",
       "82593  [(resilient, JJ), (metallurgical, JJ), (suppli...   \n",
       "82594  [(optimization, NN), (photochemical, JJ), (deg...   \n",
       "82596  [(eat, VBG), (less, JJR), (meat, NN), (save, V...   \n",
       "82597  [(algorithm, JJ), (customization, NN), (audit,...   \n",
       "\n",
       "                                             desc_tokens  \\\n",
       "0      [(develop, VBN), (new, JJ), (global, JJ), (foo...   \n",
       "1      [(digital, JJ), (transformation, NN), (resulta...   \n",
       "2      [(plastic, JJ), (pollution, NN), (planetary, J...   \n",
       "3      [(probabilistic, JJ), (estimating, NN), (time,...   \n",
       "4      [(crisis, NN), (cause, VBN), (major, JJ), (sup...   \n",
       "...                                                  ...   \n",
       "82592  [(propose, VBP), (new, JJ), (optimization, NN)...   \n",
       "82593  [(resilient, NN), (supplier, NN), (management,...   \n",
       "82594  [(objective, NN), (research, NN), (work, NN), ...   \n",
       "82596  [(publish, VBN), (healthy, JJ), (eat, VBG), (g...   \n",
       "82597  [(teaching, NN), (evaluation, NN), (apply, VBN...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [food, system, responsible, third, global, ant...  \n",
       "1      [digital, multidisciplinary, reflection, resea...  \n",
       "2      [predicted, growth, plastic, waste, exceeds, e...  \n",
       "3      [probabilistic, forecasting, autoregressive, r...  \n",
       "4      [research, opportunity, resilient, supply, cha...  \n",
       "...                                                  ...  \n",
       "82592  [stochastic, casualty, evacuation, network, de...  \n",
       "82593  [resilient, metallurgical, supplier, managemen...  \n",
       "82594  [optimization, photochemical, degradation, dai...  \n",
       "82596  [eat, less, meat, save, study, development, su...  \n",
       "82597  [algorithm, customization, audit, database, hi...  \n",
       "\n",
       "[80075 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('Data/corpus.pkl')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: number of dataframes/ calculated years/ t: 7\n"
     ]
    }
   ],
   "source": [
    "# split data into years\n",
    "dfs_by_year = split_in_time_points(corpus)\n",
    "years = len(dfs_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data at each time point and write into folders for different t\n",
    "for year in np.arange(1, years+1):\n",
    "    batch_corpus = dfs_by_year[year]\n",
    "    \n",
    "    # Save doc id plus date in file\n",
    "    doc_id_dates_df = save_doc_ids_dates(base_folder_path = 'Data/', batch_corpus = batch_corpus, year = year, save_to_folder = True)\n",
    "\n",
    "    # Add bigrams\n",
    "    batch_corpus = add_bigrams(batch_corpus)\n",
    "    \n",
    "    # Filter extreme values\n",
    "    document_list = filter_extreme_values(batch_corpus)\n",
    "\n",
    "    # Transform in octis format\n",
    "    documents_df, vocabulary = transform_in_octis_format(base_folder_path = 'Data/', document_list = document_list, t = year, save_to_folder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model Building and Selection (choose k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset1: 9815\n",
      "Length of dataset2: 11081\n",
      "Length of dataset3: 12780\n",
      "Length of dataset4: 13812\n",
      "Length of dataset5: 15092\n",
      "Length of dataset6: 16240\n",
      "Length of dataset7: 1255\n"
     ]
    }
   ],
   "source": [
    "# Have a look at corpus size for the different t\n",
    "dataset1 = load_octis_data(1)\n",
    "dataset2 = load_octis_data(2)\n",
    "dataset3 = load_octis_data(3)\n",
    "dataset4 = load_octis_data(4)\n",
    "dataset5 = load_octis_data(5)\n",
    "dataset6 = load_octis_data(6)\n",
    "dataset7 = load_octis_data(7)\n",
    "print(f'Length of dataset1: {len(dataset1.get_corpus())}')\n",
    "print(f'Length of dataset2: {len(dataset2.get_corpus())}')\n",
    "print(f'Length of dataset3: {len(dataset3.get_corpus())}')\n",
    "print(f'Length of dataset4: {len(dataset4.get_corpus())}')\n",
    "print(f'Length of dataset5: {len(dataset5.get_corpus())}')\n",
    "print(f'Length of dataset6: {len(dataset6.get_corpus())}')\n",
    "print(f'Length of dataset7: {len(dataset7.get_corpus())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for Model with k = 69: 0.4499297055236276\n",
      "Coherence Score for Model with k = 70: 0.45129722050639715\n",
      "Coherence Score for Model with k = 71: 0.4733637079426238\n",
      "Coherence Score for Model with k = 72: 0.44556061847538686\n",
      "Coherence Score for Model with k = 73: 0.45685490300073367\n",
      "Coherence Score for Model with k = 74: 0.4640863621871422\n",
      "Coherence Score for Model with k = 75: 0.4669738106663015\n",
      "Coherence Score for Model with k = 76: 0.45333456979392994\n",
      "Coherence Score for Model with k = 77: 0.4619502980706343\n",
      "Coherence Score for Model with k = 78: 0.4447683211568757\n",
      "Coherence Score for Model with k = 79: 0.4617600683340465\n",
      "Coherence Score for Model with k = 80: 0.4365703519939886\n",
      "Coherence Score for Model with k = 81: 0.4567291447253628\n",
      "Coherence Score for Model with k = 82: 0.4643782904406693\n",
      "Coherence Score for Model with k = 83: 0.45013276542928465\n",
      "Coherence Score for Model with k = 84: 0.42166109336049246\n",
      "Coherence Score for Model with k = 85: 0.4578744804467408\n",
      "Coherence Score for Model with k = 86: 0.45574002829524213\n",
      "Coherence Score for Model with k = 87: 0.4587510226695126\n",
      "Coherence Score for Model with k = 88: 0.43274433014877867\n",
      "Coherence Score for Model with k = 89: 0.43834874232374943\n",
      "Coherence Score for Model with k = 90: 0.4544884417464461\n",
      "Coherence Score for Model with k = 91: 0.45182523592239165\n",
      "Coherence Score for Model with k = 92: 0.4472971194190749\n",
      "Coherence Score for Model with k = 93: 0.42779505096362963\n",
      "Coherence Score for Model with k = 94: 0.44572582966061597\n",
      "Coherence Score for Model with k = 95: 0.4636571892290807\n",
      "Coherence Score for Model with k = 96: 0.4501118150545434\n",
      "Coherence Score for Model with k = 97: 0.4571530345750641\n",
      "Coherence Score for Model with k = 98: 0.4568266185705367\n",
      "Coherence Score for Model with k = 99: 0.4483213006945278\n",
      "Coherence Score for Model with k = 100: 0.44151302396832093\n",
      "Coherence Score for Model with k = 101: 0.43210825820712323\n",
      "Coherence Score for Model with k = 102: 0.4615830859214344\n",
      "Coherence Score for Model with k = 103: 0.4502919968464017\n",
      "Coherence Score for Model with k = 104: 0.44725150036355577\n",
      "Coherence Score for Model with k = 105: 0.4551986699788189\n",
      "Coherence Score for Model with k = 106: 0.4368108470173947\n",
      "Coherence Score for Model with k = 107: 0.45138078113396474\n",
      "Coherence Score for Model with k = 108: 0.4484044154014946\n",
      "Coherence Score for Model with k = 109: 0.4429982757617562\n",
      "Coherence Score for Model with k = 110: 0.45604472214749936\n",
      "Coherence Score for Model with k = 111: 0.43463447378464876\n",
      "Coherence Score for Model with k = 112: 0.4361814985804706\n",
      "Coherence Score for Model with k = 113: 0.44653686494129774\n",
      "Coherence Score for Model with k = 114: 0.42203797425325873\n",
      "Coherence Score for Model with k = 115: 0.45678214676619217\n",
      "Coherence Score for Model with k = 116: 0.43923489811687716\n",
      "Coherence Score for Model with k = 117: 0.4499789233284172\n",
      "Coherence Score for Model with k = 118: 0.4446799045212085\n",
      "Coherence Score for Model with k = 119: 0.43677742210720244\n",
      "Coherence Score for Model with k = 120: 0.4380159609322599\n",
      "Coherence Score for Model with k = 121: 0.443884453077283\n",
      "Coherence Score for Model with k = 122: 0.4514581765975606\n",
      "Coherence Score for Model with k = 123: 0.4348940747762271\n",
      "Coherence Score for Model with k = 124: 0.43581090472865053\n",
      "Coherence Score for Model with k = 125: 0.45042588036316894\n",
      "Coherence Score for Model with k = 126: 0.44224830448093655\n",
      "Coherence Score for Model with k = 127: 0.43535864496054416\n",
      "Coherence Score for Model with k = 128: 0.4546930106747008\n",
      "Coherence Score for Model with k = 129: 0.42666177416027423\n",
      "Coherence Score for the best model with k = 71: 0.4733637079426238\n"
     ]
    }
   ],
   "source": [
    "# Try a model for t = 1 with Mühlroth values (Repeat a few times, if it throws an error before calculating the first model)\n",
    "best_model_1, best_model_output_1, best_k_1 = find_best_model(t = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service quality logistics model game production cost party customer logistics_service\n",
      "management sustainability social green environmental research supply industry sustainable paper\n",
      "model business use change sustainable sustainability development approach study develop\n",
      "supply chain supply_chain information management competitive strategy disruption advantage global\n",
      "supply chain supply_chain study manufacturer performance result firm decision show\n",
      "online study offline return mass retailing use customization shopping online_retailer\n",
      "demand contract retailer share optimal policy revenue profit manufacturer capacity\n",
      "use study practice research paper data case management base organization\n",
      "waste management solid waste_management solid_waste use municipal energy system municipal_solid\n",
      "remanufactured increase product use remanufactured_product return vehicle study result impact\n",
      "inventory model cost demand time problem part distribution spare propose\n",
      "product quality customer coal market cost product_quality digital apparel model\n",
      "public ce sector social private safety_stock responsibility driver disruption model\n",
      "supplier selection manufacturing green criterion process supplier_selection fuzzy use study\n",
      "remanufacturing evaluation method use big process analysis hierarchy analytic base\n",
      "lean fashion cotton service study provider use brand result reactive\n",
      "network supply design chain supply_chain model use network_design study chain_network\n",
      "water energy greenhouse gas emission greenhouse_gas consumption gas_emission energy_consumption production\n",
      "use model result time material system method production problem paper\n",
      "organic farm treatment use emission conventional high ghg system study\n",
      "index model method distribution use dress ecological base corn size\n",
      "model location network decision facility approach present supply propose facility_location\n",
      "product footprint use carbon_footprint ree climate study process european case\n",
      "supply chain supply_chain research model paper study literature management framework\n",
      "product new remanufacturing customer new_product preference market channel consumer development\n",
      "carbon emission carbon_emission reduction emission_reduction tax manufacturer production game policy\n",
      "algorithm problem product approach propose use solve optimization solution model\n",
      "allocation emergency service rescue method level lean decision_support stream decision\n",
      "copper industrial use symbiosis secondary study result industrial_symbiosis aluminum product\n",
      "agricultural freight factor hospital study maritime gwp aquaculture rotation rice\n",
      "process dye wastewater electrocoagulation removal use treatment current initial ec\n",
      "emission ghg vehicle battery ghg_emission temporal spatial china intensity fuel\n",
      "use score study sustainable method bid system case thai framework\n",
      "spare use spare_part part study model system aircraft result improve\n",
      "energy input agricultural production mj output use cold analysis agricultural_product\n",
      "carbon carbon_footprint footprint cf heavy_metal use supply emission strategic low\n",
      "garment design option use body shape option_contract ecodesign base strategic_consumer\n",
      "optimal order supply inventory quantity retailer supply_chain chain numerical price\n",
      "business business_model model sustainable value industrial development environmental study industry\n",
      "plastic decentralized centralized yield aerospace mobility externality responsible marketplace operator\n",
      "car study agent paper social use uncertainty supply robustness case\n",
      "model price optimal demand pricing use dynamic control consider stochastic\n",
      "removal concentration metal electrode electrocoagulation iron efficiency use remove increase\n",
      "recycle recycling material raw rate raw_material waste metal use electronic\n",
      "production model cost optimization propose maintenance planning item total solve\n",
      "consumer strategy meat purchase model size order supplier strategic quantity\n",
      "technology cloud use student opportunity development system new paper value\n",
      "environmental impact life cycle life_cycle assessment use environmental_impact production cycle_assessment\n",
      "disaster data innovation study model emergency_resource resource use business response\n",
      "circular economy circular_economy procurement public public_procurement waste material policy end\n",
      "environmental industrial assessment impact human life use marine study method\n",
      "model body 3d result use system base different measurement method\n",
      "channel supplier selection section grey use parameter welfare process dual_channel\n",
      "system lead model use control lead_time inventory time mobile review\n",
      "production waste energy use automotive food line sustainable thermal reduce\n",
      "enterprise system performance smes small measurement software remediation book performance_measurement\n",
      "food environmental use impact land diet system dietary assessment animal\n",
      "milk dairy relief production problem result life algorithm scenario assortment\n",
      "co2 emission co2_emission deteriorate delay deterioration dioxide carbon_dioxide carbon plastic\n",
      "innovation model project development business data study use urban method\n",
      "logistics country site use_demand portfolio thailand use global rationality edible\n",
      "material use fiber carbon increase property production high composite result\n",
      "model forecast use data propose time method series blood forecasting\n",
      "textile clothing production export use water large textile_clothing high industry\n",
      "artificial technology new model artificial_neural strategic business management ann neural\n",
      "logistics reverse reverse_logistics paper use transport process model base system\n",
      "design energy renewable resource system product new industrial technology innovative\n",
      "supply chain supply_chain bullwhip effect use decision bullwhip_effect research sustainability\n",
      "risk financing asymmetric supply chain aversion model default credit supplier\n",
      "national security diet railway new development platform power space team\n",
      "information rare earth rare_earth share data scrap health industrial information_share\n",
      "Coherence Score for Model with k = 71: 0.4733637079426238\n"
     ]
    }
   ],
   "source": [
    "# View Topics\n",
    "for topic in best_model_output_1['topics']:\n",
    "    print(' '.join(topic))\n",
    "coherence = calculate_coherence(model_output = best_model_output_1, t = 1)\n",
    "print(f'Coherence Score for Model with k = {best_k_1}: {coherence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Update Model with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for Model with k = 5: 0.4842783276421262\n",
      "Coherence Score for Model with k = 10: 0.5362210068433599\n",
      "Coherence Score for Model with k = 15: 0.49447651766606343\n",
      "Coherence Score for Model with k = 20: 0.533871814171566\n",
      "Coherence Score for Model with k = 25: 0.5503197725453807\n",
      "Coherence Score for Model with k = 30: 0.5025987111781155\n",
      "Coherence Score for the best model with k = 25: 0.5503197725453807\n"
     ]
    }
   ],
   "source": [
    "# Reevaluate model with new data at t = 2 with test range of k = [5, 10, 15, 20, 25, 30]\n",
    "best_model_2, best_model_output_2, best_k_2= find_best_model(t = 2, test_range = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for Model using old k = 25: 0.5076807151990521\n",
      "This coherence of 0.5076807151990521 is worse than the old coherence of 0.5503197725453807.\n",
      "Finding new model...\n",
      "\n",
      "Coherence Score for Model with k = 5: 0.5169903179764579\n",
      "Coherence Score for Model with k = 10: 0.5239696855742813\n",
      "Coherence Score for Model with k = 15: 0.5306139024299402\n",
      "Coherence Score for Model with k = 20: 0.5471145448274553\n",
      "Coherence Score for Model with k = 25: 0.5026885130686735\n",
      "Coherence Score for Model with k = 30: 0.5294691916960421\n",
      "Coherence Score for the best model with k = 20: 0.5471145448274553\n",
      "Coherence Score for Model using a new best k = 20: 0.5471145448274553\n",
      "This coherence for k = 20 of 0.5471145448274553 is still worse than the old coherence of 0.5503197725453807.\n",
      "Continue to use old k of 25.\n"
     ]
    }
   ],
   "source": [
    "coherence_2 = calculate_coherence(model_output = best_model_output_2, t = 2)\n",
    "# Update Model at time point t = 3\n",
    "best_model_3, best_model_output_3, best_k_3 = update_model(t_now = 3, old_coherence = coherence_2, old_k = best_k_2, test_range = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score for Model using old k = 25: 0.5312710714747276\n",
      "This coherence of 0.5312710714747276 is better than the old coherence of 0.5076807151990521.\n",
      "Continue to use old k of 25.\n"
     ]
    }
   ],
   "source": [
    "coherence_3 = calculate_coherence(model_output = best_model_output_3, t = 3)\n",
    "# Update Model at time point t = 4\n",
    "best_model_4, best_model_output_4, best_k_4 = update_model(t_now = 4, old_coherence = coherence_3, old_k = best_k_3, test_range = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Emergence Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic emergences:  {0: 'emerging', 1: 'emerging', 2: 'popular', 3: 'popular', 4: 'popular', 5: 'emerging', 6: 'emerging', 7: 'emerging', 8: 'popular', 9: 'popular', 10: 'emerging', 11: 'popular', 12: 'emerging', 13: 'emerging', 14: 'emerging', 15: 'emerging', 16: 'popular', 17: 'emerging', 18: 'popular', 19: 'emerging', 20: 'popular', 21: 'emerging', 22: 'popular', 23: 'emerging', 24: 'emerging'}\n",
      "These are the emerging topics:\n",
      "\n",
      "['supplier', 'performance', 'company', 'selection', 'sustainability', 'sustainable', 'information', 'use', 'criterion', 'study']\n",
      "['material', 'organic', 'use', 'clothing', 'mineral', 'system', 'size', 'pattern', 'import', 'raw']\n",
      "['design', 'learn', 'product', 'learning', 'quality', 'student', 'paper', 'improve', 'safety', 'use']\n",
      "['method', 'use', 'forecast', 'green', 'time', 'result', 'data', 'base', 'study', 'propose']\n",
      "['production', 'use', 'environmental', 'increase', 'metal', 'system', 'textile', 'economic', 'impact', 'study']\n",
      "['carbon', 'emission', 'carbon_emission', 'use', 'dye', 'consumer', 'result', 'reduction', 'reactive', 'data']\n",
      "['model', 'use', 'removal', 'treatment', 'process', 'time', 'electrocoagulation', 'water', 'result', 'wastewater']\n",
      "['product', 'system', 'use', 'return', 'production', 'time', 'demand', 'study', 'result', 'mitigation']\n",
      "['circular', 'economy', 'circular_economy', 'industry', 'material', 'paper', 'value', 'lean', 'process', 'company']\n",
      "['food', 'value', 'service', 'use', 'water', 'system', 'model', 'nutritional', 'study', 'analysis']\n",
      "['remanufacturing', 'part', 'maintenance', 'product', 'spare', 'system', 'spare_part', 'consumer', 'use', 'online']\n",
      "['food', 'food_waste', 'vegetable', 'fresh', 'biodiversity', 'system', 'health', 'sale', 'measurement', 'fruit']\n",
      "['meat', 'diet', 'animal', 'food', 'public', 'consumption', 'procurement', 'dietary', 'vegetarian', 'sustainable']\n",
      "['fiber', 'material', 'recycle', 'plastic', 'use', 'composite', 'property', 'recycling', 'mechanical', 'recycled']\n",
      "['service', 'use', 'model', 'human', 'base', 'cold_chain', 'quality', 'cold', 'body', 'measurement']\n"
     ]
    }
   ],
   "source": [
    "# find emerging topics at t = 3\n",
    "# Mühlroth & Grottke suggested pi = 0.3625 but sometimes a less conservative value (larger pi) has to be used to find emerging topics! \n",
    "topics_emerging_popular = find_emerging_topics(model_new = best_model_3, model_output_new = best_model_output_3, \n",
    "                                               model_old = best_model_2, model_output_old = best_model_output_2, pi = 0.7)\n",
    "print('Topic emergences: ', topics_emerging_popular)\n",
    "\n",
    "# View emerging topics\n",
    "print('These are the emerging topics:\\n')\n",
    "for k in topics_emerging_popular:\n",
    "    if topics_emerging_popular[k] == 'emerging':\n",
    "        print(best_model_output_3['topics'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Trend Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending vs. declining topics:  {0: 'declining', 1: 'declining', 2: 'trending', 3: 'declining', 4: 'trending', 5: 'declining', 6: 'trending', 7: 'declining', 8: 'trending', 9: 'trending', 10: 'declining', 11: 'declining', 12: 'trending', 13: 'declining', 14: 'declining', 15: 'declining', 16: 'trending', 17: 'declining', 18: 'trending', 19: 'declining', 20: 'trending', 21: 'trending', 22: 'trending', 23: 'declining', 24: 'trending'}\n",
      "These are the emerging + trending topics:\n",
      "\n",
      "['method', 'use', 'forecast', 'green', 'time', 'result', 'data', 'base', 'study', 'propose']\n",
      "['model', 'use', 'removal', 'treatment', 'process', 'time', 'electrocoagulation', 'water', 'result', 'wastewater']\n",
      "['meat', 'diet', 'animal', 'food', 'public', 'consumption', 'procurement', 'dietary', 'vegetarian', 'sustainable']\n",
      "['service', 'use', 'model', 'human', 'base', 'cold_chain', 'quality', 'cold', 'body', 'measurement']\n"
     ]
    }
   ],
   "source": [
    "# Find trending topics\n",
    "topics_trending = find_trending_topics(model_output=best_model_output_3, t=3)\n",
    "print('Trending vs. declining topics: ', topics_trending)\n",
    "\n",
    "# Find topics that are emerging & trending => Establish strategy!\n",
    "print('These are the emerging + trending topics:\\n')\n",
    "for k in topics_trending:\n",
    "    if topics_trending[k] == 'trending' and topics_emerging_popular[k] == 'emerging':\n",
    "        print(best_model_output_3['topics'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growth     declining  trending\n",
      "Emergence                     \n",
      "emerging          11         4\n",
      "popular            2         8\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the dictionaries\n",
    "topics_df = pd.DataFrame({\n",
    "    'Emergence': topics_emerging_popular,\n",
    "    'Growth': topics_trending\n",
    "})\n",
    "\n",
    "# Create a pivot table to get the matrix\n",
    "pivot_table = topics_df.pivot_table(index='Emergence', columns='Growth', aggfunc='size', fill_value=0)\n",
    "print(pivot_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsa-etm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
